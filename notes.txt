The app fimds dupliate images in a folder and its subfolders and generates a JSON report of the duplicates.

Image representation:
====================

An image is represented by a Struct `Image` that contains the path to the file.
Expensive operations like hashing and metadata extraction are done lazily.

`Image` provides the following methods:

- from_path(path: str) -> Image: creates an Image from a path
- is_valid() -> bool: returns True if the image is valid
- has_sidecar() -> bool: returns True if the image has a sidecar file
- image() -> Image: returns the image, ensuring that it is not rotated
- resolution() -> Tuple[int, int]: returns the resolution of the image
- aspect_ratio() -> float: returns the aspect ratio of the image
- metadata() -> Dict[str, Any]: returns the metadata of the image e.g. gps location
- hash() -> str: returns the hash of the image
- similarity(other: Image) -> float: returns the similarity of the image to another image

Image is hashable and comparable.

Similarity detection:
====================

Images are converted to greyscale and resized to be the same dimensions. SSIM is computed from variance and covariance of the images.


Duplicate detection:
====================

Two criteria for duplicate images are:
- images with the same hash
- images are structurally similar

The detection algorithm is as follows. We compare each image to every other image and compute the similarty index. We use a datastructure that uses the hash of image path as the key and a vector of image paths that are similar. To speed up comparison, we use a cache to store the similarity index of images that have already been compared.


Additional considerations:
=========================

Where duplictes are found, the app should keep the image with the highest resolution.

Metadata from the other images should be preserved, expecially geolocation. The app needs to manage conflicts.



Aproach 2:
==========

Brute force image structural similarity comparison is slow and memory intensive. We can use a more efficient approach by using a perceptual hash to compare images. We can use the hamming distance between the hashes to determine similarity. We can then use a clustering algorithm to group similar images together.

Also, the problem space can be reduced by identifying and removing images with an identical image hash. This will reduce the number of images that need to be compared with the structural similarity algorithm.

Method:

1. Compute the hash of each image
2. Compute groups of identical hashes
3. Generate a report of the duplicates
